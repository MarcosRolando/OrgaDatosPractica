{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1) Una importante empresa de reventa de dispositivos electrónicos se\n",
    "encuentra realizando preparativos para el próximo Black Friday en su\n",
    "canal de ecommerce. Como parte de su equipo de análisis de datos tu\n",
    "misión es calcular la siguientes métricas usando pyspark:\n",
    "\n",
    "A) Tiempo de sesión promedio de usuarios en el sitio. (siendo\n",
    "el tiempo de una sesión de un usuario el tiempo acumulado\n",
    "de todos sus eventos para cada sesión) (7 puntos) #asumo que quiere el tiempo promedio de sesion de cada usuario\n",
    "\n",
    "B) Bounce Rate (cantidad de sesiones que solamente\n",
    "realizaron un evento % cantidad de sesiones totales) (13\n",
    "puntos)\n",
    "\n",
    "Esto debe realizarse a partir de la información recolectada por su\n",
    "plataforma de analytics la cual es accesible en un RDD del siguiente\n",
    "formato (id_de_cliente, id_de_sesion, url,\n",
    "tipo_de_evento, metadata,\n",
    "tiempo_transcurrido_desde_anterior_evento).\n",
    "(****) ( 20pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353.5013623978202"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "\n",
    "# create the Spark Session\n",
    "spark = ps.sql.SparkSession.builder.getOrCreate()\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "salesRdd = spark.read.csv('/home/marcos/PycharmProjects/PracticaSpark/Parciales/eventos.csv', header=True).rdd\n",
    "\n",
    "salesRdd = salesRdd.map(lambda x: (pd.to_numeric(x[0], 'coerce'), pd.to_numeric(x[1], 'coerce')\n",
    "                                   , x[2], x[3], x[4], pd.to_numeric(x[5], 'coerce'))).filter(lambda x: x[3] is not None).cache()\n",
    "\n",
    "sessionsAndTime = salesRdd.map(lambda x: ((x[0], x[1]), x[5])).reduceByKey(lambda x,y: x + y) \\\n",
    "        .map(lambda x: (x[1], 1)).reduce(lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
    "\n",
    "sessionsAndTime[0] / sessionsAndTime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956403269754768"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessionsWithOneEvent = salesRdd.map(lambda x: ((x[0], x[1]), 1)).reduceByKey(lambda x,y: x + y) \\\n",
    "        .filter(lambda x: x[1] == 1).count()\n",
    "\n",
    "sessionsWithOneEvent / sessionsAndTime[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}