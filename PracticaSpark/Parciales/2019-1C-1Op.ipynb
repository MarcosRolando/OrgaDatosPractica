{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1) El servicio meteorológico registra datos del\n",
    "tiempo para todas las ciudades donde posee\n",
    "una base de medición.\n",
    "Esta información se encuentra en dos RDD.\n",
    "En el primero se tiene información de las\n",
    "bases de medición: (ID_BASE, NOMBRE,\n",
    "PCIA, CIUDAD, LAT, LON).\n",
    "El segundo posee información sobre las\n",
    "mediciones en sí: (TIMESTAMP, ID_BASE,\n",
    "TEMPERATURA, HUMEDAD, PRESIÓN,\n",
    "DIRECCIÓN VIENTO, VELOCIDAD VIENTO).\n",
    "\n",
    "Se desea obtener un reporte para las bases de\n",
    "la Provincia de Buenos Aires. El mismo debe\n",
    "informar los ID y nombre de bases de\n",
    "medición que hayan registrado una variación\n",
    "de temperatura promedio mensual mayor al\n",
    "30% en el año 2018 (dada la temperatura\n",
    "promedio de un mes, esta se debe comparar\n",
    "con el promedio del mes anterior, para\n",
    "determinar la variación porcentual).\n",
    "Resolver utilizando el API de RDD de\n",
    "PySpark, dando el reporte en un RDD. (***) (\n",
    "15pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[((5, 4, 'oucmkxnka'), (23.77777777777778, 26.0)),\n ((5, 8, 'oucmkxnka'), (25.46153846153846, 29.4)),\n ((3, 7, 'dcqyupw'), (20.6, 12.375)),\n ((3, 11, 'dcqyupw'), (23.571428571428573, 18.142857142857142)),\n ((3, 3, 'dcqyupw'), (14.75, 22.571428571428573)),\n ((3, 6, 'dcqyupw'), (22.0, 20.6)),\n ((3, 10, 'dcqyupw'), (23.857142857142858, 23.571428571428573)),\n ((3, 2, 'dcqyupw'), (28.0, 14.75)),\n ((5, 9, 'oucmkxnka'), (29.4, 14.454545454545455)),\n ((5, 1, 'oucmkxnka'), (19.642857142857142, 21.733333333333334)),\n ((5, 5, 'oucmkxnka'), (26.0, 27.5)),\n ((3, 1, 'dcqyupw'), (24.0, 28.0)),\n ((3, 5, 'dcqyupw'), (17.1, 22.0)),\n ((3, 9, 'dcqyupw'), (15.9, 23.857142857142858)),\n ((5, 6, 'oucmkxnka'), (27.5, 16.375)),\n ((5, 2, 'oucmkxnka'), (21.733333333333334, 13.166666666666666)),\n ((5, 10, 'oucmkxnka'), (14.454545454545455, 14.375)),\n ((5, 3, 'oucmkxnka'), (13.166666666666666, 23.77777777777778)),\n ((5, 7, 'oucmkxnka'), (16.375, 25.46153846153846)),\n ((5, 11, 'oucmkxnka'), (14.375, 15.666666666666666)),\n ((3, 8, 'dcqyupw'), (12.375, 15.9)),\n ((3, 4, 'dcqyupw'), (22.571428571428573, 17.1))]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "\n",
    "# create the Spark Session\n",
    "spark = ps.sql.SparkSession.builder.getOrCreate()\n",
    "# create the Spark Context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "aux = sc.textFile('/home/marcos/PycharmProjects/PracticaSpark/Parciales/P2019-1C-1Op.csv')\n",
    "basesRdd = aux.map(lambda x: x.split(\",\"))\n",
    "basesRdd = basesRdd.map(lambda x: (pd.to_numeric(x[0], 'coerce'), x[1], x[2], x[3],\n",
    "                                 pd.to_numeric(x[4], 'coerce'), pd.to_numeric(x[5], 'coerce')))\n",
    "\n",
    "aux = sc.textFile('/home/marcos/PycharmProjects/PracticaSpark/Parciales/P2019-1C-1OpMediciones.csv')\n",
    "meditionsRdd = aux.map(lambda x: x.split(\",\"))\n",
    "meditionsRdd = meditionsRdd.map(lambda x: (pd.to_datetime(x[0], 'coerce', format='%Y-%m-%d'),\n",
    "                                           pd.to_numeric(x[1], 'coerce'), pd.to_numeric(x[2], 'coerce'),\n",
    "                                           pd.to_numeric(x[3], 'coerce'), pd.to_numeric(x[4], 'coerce'),\n",
    "                                            x[5], pd.to_numeric(x[6], 'coerce')))\n",
    "\n",
    "buenosAiresBases = basesRdd.filter(lambda x: x[2] == 'Buenos Aires').map(lambda x: (x[0], x[1]))\n",
    "\n",
    "monthlyAveragePerBase = meditionsRdd.map(lambda x: (x[1], (x[0], x[2]))).join(buenosAiresBases).\\\n",
    "            filter(lambda x: x[1][0][0].year == 2018).map(lambda x: ((x[0], x[1][0][0].month, x[1][1]), (x[1][0][1], 1))) \\\n",
    "            .reduceByKey(lambda x,y: (x[0] + y[0], x[1] + y[1])).mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "#groupedData = monthlyAveragePerBase.map(lambda x: ((x[0][0], x[0][2]), (x[0][1], x[1]))).groupByKey()\n",
    "\n",
    "'''\n",
    "def f(x):\n",
    "    monthly_temp = list(x)\n",
    "    monthly_temp.sort()\n",
    "    for i in range(0, len(monthly_temp) - 1):\n",
    "        if (monthly_temp[i+1][0] - monthly_temp[i][0]) == 1 :\n",
    "            if (abs(monthly_temp[i][1] - monthly_temp[i+1][1]) / monthly_temp[i][1]) > 0.3:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "groupedData.mapValues(f).filter(lambda x: x[1] == True).map(lambda x: (x[0][0], x[0][1])).collect()\n",
    "'''\n",
    "\n",
    "def f(x,y):\n",
    "    if x[0] is not None:\n",
    "        return x[0], y[1]\n",
    "    return y[0], x[1]\n",
    "\n",
    "monthlyAveragePerBase.flatMap(lambda x: ( (x[0], (x[1], None)), ((x[0][0], x[0][1] - 1, x[0][2]), (None, x[1])) )) \\\n",
    "                    .reduceByKey(f).filter(lambda x: (x[1][0] is not None) & (x[1][1] is not None))\\\n",
    "                    .filter(lambda x: abs((x[1][0] - x[1][1]) / x[1][0]) > 0.3).map(lambda x: (x[0][0], x[0][2])) \\\n",
    "                    .distinct().collect()\n",
    "#Opinion: la solucion sin el groupBy me parece una verga y hasta mas ineficiente, pero parece que ellos prefieren eso"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}